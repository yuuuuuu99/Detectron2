{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"detectron2_balloon.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"a4AoqK-xiNeu","executionInfo":{"status":"ok","timestamp":1604900266932,"user_tz":-480,"elapsed":9582,"user":{"displayName":"曾珮瑜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPYSYGADc29eZMBqL2Y0yOZut6dqSPIMQ8_DJEacQ=s64","userId":"12040478592812319513"}},"outputId":"c033cbea-f74a-4275-c5f8-59835c128fc9","colab":{"base_uri":"https://localhost:8080/"}},"source":["# install dependencies: \n","!pip install pyyaml==5.1 pycocotools>=2.0.1\n","import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())\n","!gcc --version\n","# opencv is pre-installed on colab"],"execution_count":1,"outputs":[{"output_type":"stream","text":["1.7.0+cu101 True\n","gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","Copyright (C) 2017 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0u-GIRAyiZMp","executionInfo":{"status":"ok","timestamp":1604900318085,"user_tz":-480,"elapsed":8616,"user":{"displayName":"曾珮瑜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPYSYGADc29eZMBqL2Y0yOZut6dqSPIMQ8_DJEacQ=s64","userId":"12040478592812319513"}},"outputId":"cf31a1de-2d72-4dff-cc3b-69c4048b15ff","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# install detectron2: (Colab has CUDA 10.1 + torch 1.6)\n","# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n","assert torch.__version__.startswith(\"1.7\")\n","!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/index.html"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/index.html\n","Collecting detectron2\n","\u001b[?25l  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/detectron2-0.3%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n","\u001b[K     |████████████████████████████████| 6.6MB 697kB/s \n","\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.1.0)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2) (4.41.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.8.7)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2) (3.2.2)\n","Collecting yacs>=0.1.6\n","  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.3.0)\n","Collecting Pillow>=7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/19/d4c25111d36163698396f93c363114cf1cddbacb24744f6612f25b6aa3d0/Pillow-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.2MB 4.7MB/s \n","\u001b[?25hRequirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.0.2)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n","Collecting fvcore>=0.1.2\n","  Downloading https://files.pythonhosted.org/packages/e7/37/82dc217199c10288f3d05f50f342cb270ff2630841734bdfa40b54b0f8bc/fvcore-0.1.2.post20201104.tar.gz\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.16.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.3.1)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.18.5)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2) (5.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.10.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.33.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.3.3)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.35.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (50.3.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.7.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.17.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.4.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (2.23.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.12.4)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.15.0)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.2->detectron2) (0.29.21)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (2.0.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.1.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2) (3.4.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.0)\n","Building wheels for collected packages: fvcore\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.2.post20201104-cp36-none-any.whl size=44419 sha256=07d79be43c96f024cfb16f2f70d74e2b8ec0f3c4e56f708ce3452499ec933cbf\n","  Stored in directory: /root/.cache/pip/wheels/ec/4d/40/4077356fe02ef345791713eabede5ed63afe7d613b016694d1\n","Successfully built fvcore\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: yacs, Pillow, portalocker, fvcore, detectron2\n","  Found existing installation: Pillow 7.0.0\n","    Uninstalling Pillow-7.0.0:\n","      Successfully uninstalled Pillow-7.0.0\n","Successfully installed Pillow-8.0.1 detectron2-0.3+cu101 fvcore-0.1.2.post20201104 portalocker-2.0.0 yacs-0.1.8\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"7VCyn4y7ikYj","executionInfo":{"status":"ok","timestamp":1604900329916,"user_tz":-480,"elapsed":2021,"user":{"displayName":"曾珮瑜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPYSYGADc29eZMBqL2Y0yOZut6dqSPIMQ8_DJEacQ=s64","userId":"12040478592812319513"}}},"source":["import detectron2\n","import numpy as np\n","import json\n","import cv2\n","import random\n","import os\n","\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog\n","from detectron2.data import DatasetCatalog\n","from detectron2.engine import DefaultTrainer\n","from detectron2.structures import BoxMode\n","from detectron2.utils.visualizer import ColorMode\n","\n","from matplotlib import pyplot as plt\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"vzhVQ7gAipd-","executionInfo":{"status":"ok","timestamp":1604900335051,"user_tz":-480,"elapsed":753,"user":{"displayName":"曾珮瑜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPYSYGADc29eZMBqL2Y0yOZut6dqSPIMQ8_DJEacQ=s64","userId":"12040478592812319513"}},"outputId":"bd52aacb-7575-48dc-d607-d9ffd58379e3","colab":{"base_uri":"https://localhost:8080/"}},"source":["DatasetCatalog.list()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['coco_2014_train',\n"," 'coco_2014_val',\n"," 'coco_2014_minival',\n"," 'coco_2014_minival_100',\n"," 'coco_2014_valminusminival',\n"," 'coco_2017_train',\n"," 'coco_2017_val',\n"," 'coco_2017_test',\n"," 'coco_2017_test-dev',\n"," 'coco_2017_val_100',\n"," 'keypoints_coco_2014_train',\n"," 'keypoints_coco_2014_val',\n"," 'keypoints_coco_2014_minival',\n"," 'keypoints_coco_2014_valminusminival',\n"," 'keypoints_coco_2014_minival_100',\n"," 'keypoints_coco_2017_train',\n"," 'keypoints_coco_2017_val',\n"," 'keypoints_coco_2017_val_100',\n"," 'coco_2017_train_panoptic_separated',\n"," 'coco_2017_train_panoptic_stuffonly',\n"," 'coco_2017_train_panoptic',\n"," 'coco_2017_val_panoptic_separated',\n"," 'coco_2017_val_panoptic_stuffonly',\n"," 'coco_2017_val_panoptic',\n"," 'coco_2017_val_100_panoptic_separated',\n"," 'coco_2017_val_100_panoptic_stuffonly',\n"," 'coco_2017_val_100_panoptic',\n"," 'lvis_v1_train',\n"," 'lvis_v1_val',\n"," 'lvis_v1_test_dev',\n"," 'lvis_v1_test_challenge',\n"," 'lvis_v0.5_train',\n"," 'lvis_v0.5_val',\n"," 'lvis_v0.5_val_rand_100',\n"," 'lvis_v0.5_test',\n"," 'lvis_v0.5_train_cocofied',\n"," 'lvis_v0.5_val_cocofied',\n"," 'cityscapes_fine_instance_seg_train',\n"," 'cityscapes_fine_sem_seg_train',\n"," 'cityscapes_fine_instance_seg_val',\n"," 'cityscapes_fine_sem_seg_val',\n"," 'cityscapes_fine_instance_seg_test',\n"," 'cityscapes_fine_sem_seg_test',\n"," 'cityscapes_fine_panoptic_train',\n"," 'cityscapes_fine_panoptic_val',\n"," 'voc_2007_trainval',\n"," 'voc_2007_train',\n"," 'voc_2007_val',\n"," 'voc_2007_test',\n"," 'voc_2012_trainval',\n"," 'voc_2012_train',\n"," 'voc_2012_val',\n"," 'ade20k_sem_seg_train',\n"," 'ade20k_sem_seg_val']"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"WG3V2yqDi8E4","executionInfo":{"status":"ok","timestamp":1604900339428,"user_tz":-480,"elapsed":642,"user":{"displayName":"曾珮瑜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPYSYGADc29eZMBqL2Y0yOZut6dqSPIMQ8_DJEacQ=s64","userId":"12040478592812319513"}},"outputId":"4135fc2a-7248-464b-ffdd-c8637d5903ca","colab":{"base_uri":"https://localhost:8080/"}},"source":["MetadataCatalog.get('cityscapes_fine_instance_seg_train')\n"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Metadata(evaluator_type='cityscapes_instance', gt_dir='datasets/cityscapes/gtFine/train/', image_dir='datasets/cityscapes/leftImg8bit/train/', name='cityscapes_fine_instance_seg_train', stuff_classes=['road', 'sidewalk', 'building', 'wall', 'fence', 'pole', 'traffic light', 'traffic sign', 'vegetation', 'terrain', 'sky', 'person', 'rider', 'car', 'truck', 'bus', 'train', 'motorcycle', 'bicycle'], thing_classes=['person', 'rider', 'car', 'truck', 'bus', 'train', 'motorcycle', 'bicycle'])"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"2hg4q80bjAQ6","executionInfo":{"status":"ok","timestamp":1604900343056,"user_tz":-480,"elapsed":654,"user":{"displayName":"曾珮瑜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPYSYGADc29eZMBqL2Y0yOZut6dqSPIMQ8_DJEacQ=s64","userId":"12040478592812319513"}},"outputId":"42291351-7790-4c83-896c-7840f8b591ac","colab":{"base_uri":"https://localhost:8080/"}},"source":["MetadataCatalog.get('keypoints_coco_2017_train').thing_classes"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['person']"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"p1uSvBZ_jDmJ","executionInfo":{"status":"ok","timestamp":1604900348655,"user_tz":-480,"elapsed":1982,"user":{"displayName":"曾珮瑜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPYSYGADc29eZMBqL2Y0yOZut6dqSPIMQ8_DJEacQ=s64","userId":"12040478592812319513"}},"outputId":"0e4a41c9-303e-4aed-841f-4e6e0a55046f","colab":{"base_uri":"https://localhost:8080/"}},"source":["!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip\n","!unzip balloon_dataset.zip > /dev/null"],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2020-11-09 05:39:06--  https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip\n","Resolving github.com (github.com)... 140.82.113.4\n","Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/737339e2-2b83-11e8-856a-188034eb3468?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20201109%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20201109T053906Z&X-Amz-Expires=300&X-Amz-Signature=b2d15ec097fd03677bdf227bbf4455f1d08ef95ce11f1fddbfba6739572e27d9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=107595270&response-content-disposition=attachment%3B%20filename%3Dballoon_dataset.zip&response-content-type=application%2Foctet-stream [following]\n","--2020-11-09 05:39:06--  https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/737339e2-2b83-11e8-856a-188034eb3468?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20201109%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20201109T053906Z&X-Amz-Expires=300&X-Amz-Signature=b2d15ec097fd03677bdf227bbf4455f1d08ef95ce11f1fddbfba6739572e27d9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=107595270&response-content-disposition=attachment%3B%20filename%3Dballoon_dataset.zip&response-content-type=application%2Foctet-stream\n","Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.169.235\n","Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.169.235|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 38741381 (37M) [application/octet-stream]\n","Saving to: ‘balloon_dataset.zip’\n","\n","balloon_dataset.zip 100%[===================>]  36.95M  61.2MB/s    in 0.6s    \n","\n","2020-11-09 05:39:07 (61.2 MB/s) - ‘balloon_dataset.zip’ saved [38741381/38741381]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mnLxAmDijJ0g","executionInfo":{"status":"ok","timestamp":1604900353258,"user_tz":-480,"elapsed":697,"user":{"displayName":"曾珮瑜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPYSYGADc29eZMBqL2Y0yOZut6dqSPIMQ8_DJEacQ=s64","userId":"12040478592812319513"}}},"source":["def get_balloon_dicts(img_dir):\n","    json_file = os.path.join(img_dir, \"via_region_data.json\")\n","    with open(json_file) as f:\n","        imgs_anns = json.load(f)\n","\n","    dataset_dicts = []\n","    for idx, v in enumerate(imgs_anns.values()):\n","        record = {}\n","        \n","        filename = os.path.join(img_dir, v[\"filename\"])\n","        height, width = cv2.imread(filename).shape[:2]\n","        \n","        record[\"file_name\"] = filename\n","        record[\"image_id\"] = idx\n","        record[\"height\"] = height\n","        record[\"width\"] = width\n","      \n","        annos = v[\"regions\"]\n","        objs = []\n","        for _, anno in annos.items():\n","            assert not anno[\"region_attributes\"]\n","            anno = anno[\"shape_attributes\"]\n","            px = anno[\"all_points_x\"]\n","            py = anno[\"all_points_y\"]\n","            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n","            poly = [p for x in poly for p in x]\n","\n","            obj = {\n","                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n","                \"bbox_mode\": BoxMode.XYXY_ABS,\n","                \"segmentation\": [poly],\n","                \"category_id\": 0,\n","                \"iscrowd\": 0\n","            }\n","            objs.append(obj)\n","        record[\"annotations\"] = objs\n","        dataset_dicts.append(record)\n","    return dataset_dicts\n","\n","\n","for d in [\"train\", \"val\"]:\n","    DatasetCatalog.register(\"balloon_\" + d, lambda d=d: get_balloon_dicts(\"balloon/\" + d))\n","    MetadataCatalog.get(\"balloon_\" + d).set(thing_classes=[\"balloon\"])\n","balloon_metadata = MetadataCatalog.get(\"balloon_train\")\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWpNVvN1jMLd","executionInfo":{"status":"ok","timestamp":1604900357590,"user_tz":-480,"elapsed":685,"user":{"displayName":"曾珮瑜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPYSYGADc29eZMBqL2Y0yOZut6dqSPIMQ8_DJEacQ=s64","userId":"12040478592812319513"}},"outputId":"c87ada96-646f-4300-cc09-00ab0f572267","colab":{"base_uri":"https://localhost:8080/"}},"source":["balloon_metadata\n"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Metadata(name='balloon_train', thing_classes=['balloon'])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"PIJOsn84jOsa","executionInfo":{"status":"ok","timestamp":1604900360971,"user_tz":-480,"elapsed":586,"user":{"displayName":"曾珮瑜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPYSYGADc29eZMBqL2Y0yOZut6dqSPIMQ8_DJEacQ=s64","userId":"12040478592812319513"}},"outputId":"45cd13b8-e9fa-45b0-b4c5-16534abcfda1","colab":{"base_uri":"https://localhost:8080/"}},"source":["MetadataCatalog.get(\"balloon_val\")"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Metadata(name='balloon_val', thing_classes=['balloon'])"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"D2GnTfACjRj0","executionInfo":{"status":"ok","timestamp":1604900364763,"user_tz":-480,"elapsed":593,"user":{"displayName":"曾珮瑜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPYSYGADc29eZMBqL2Y0yOZut6dqSPIMQ8_DJEacQ=s64","userId":"12040478592812319513"}},"outputId":"e3eb3125-b84d-494c-8acb-95719ad0f8f1","colab":{"base_uri":"https://localhost:8080/"}},"source":["DatasetCatalog.list()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['coco_2014_train',\n"," 'coco_2014_val',\n"," 'coco_2014_minival',\n"," 'coco_2014_minival_100',\n"," 'coco_2014_valminusminival',\n"," 'coco_2017_train',\n"," 'coco_2017_val',\n"," 'coco_2017_test',\n"," 'coco_2017_test-dev',\n"," 'coco_2017_val_100',\n"," 'keypoints_coco_2014_train',\n"," 'keypoints_coco_2014_val',\n"," 'keypoints_coco_2014_minival',\n"," 'keypoints_coco_2014_valminusminival',\n"," 'keypoints_coco_2014_minival_100',\n"," 'keypoints_coco_2017_train',\n"," 'keypoints_coco_2017_val',\n"," 'keypoints_coco_2017_val_100',\n"," 'coco_2017_train_panoptic_separated',\n"," 'coco_2017_train_panoptic_stuffonly',\n"," 'coco_2017_train_panoptic',\n"," 'coco_2017_val_panoptic_separated',\n"," 'coco_2017_val_panoptic_stuffonly',\n"," 'coco_2017_val_panoptic',\n"," 'coco_2017_val_100_panoptic_separated',\n"," 'coco_2017_val_100_panoptic_stuffonly',\n"," 'coco_2017_val_100_panoptic',\n"," 'lvis_v1_train',\n"," 'lvis_v1_val',\n"," 'lvis_v1_test_dev',\n"," 'lvis_v1_test_challenge',\n"," 'lvis_v0.5_train',\n"," 'lvis_v0.5_val',\n"," 'lvis_v0.5_val_rand_100',\n"," 'lvis_v0.5_test',\n"," 'lvis_v0.5_train_cocofied',\n"," 'lvis_v0.5_val_cocofied',\n"," 'cityscapes_fine_instance_seg_train',\n"," 'cityscapes_fine_sem_seg_train',\n"," 'cityscapes_fine_instance_seg_val',\n"," 'cityscapes_fine_sem_seg_val',\n"," 'cityscapes_fine_instance_seg_test',\n"," 'cityscapes_fine_sem_seg_test',\n"," 'cityscapes_fine_panoptic_train',\n"," 'cityscapes_fine_panoptic_val',\n"," 'voc_2007_trainval',\n"," 'voc_2007_train',\n"," 'voc_2007_val',\n"," 'voc_2007_test',\n"," 'voc_2012_trainval',\n"," 'voc_2012_train',\n"," 'voc_2012_val',\n"," 'ade20k_sem_seg_train',\n"," 'ade20k_sem_seg_val',\n"," 'balloon_train',\n"," 'balloon_val']"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"Nms9qZP9jU99","executionInfo":{"status":"ok","timestamp":1604900371202,"user_tz":-480,"elapsed":2392,"user":{"displayName":"曾珮瑜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPYSYGADc29eZMBqL2Y0yOZut6dqSPIMQ8_DJEacQ=s64","userId":"12040478592812319513"}},"outputId":"3142b87d-bc36-43cf-dbdf-7c8444947054","colab":{"base_uri":"https://localhost:8080/"}},"source":["DatasetCatalog.get('balloon_train')[0]"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'annotations': [{'bbox': [994, 619, 1445, 1166],\n","   'bbox_mode': <BoxMode.XYXY_ABS: 0>,\n","   'category_id': 0,\n","   'iscrowd': 0,\n","   'segmentation': [[1020.5,\n","     963.5,\n","     1000.5,\n","     899.5,\n","     994.5,\n","     841.5,\n","     1003.5,\n","     787.5,\n","     1023.5,\n","     738.5,\n","     1050.5,\n","     700.5,\n","     1089.5,\n","     663.5,\n","     1134.5,\n","     638.5,\n","     1190.5,\n","     621.5,\n","     1265.5,\n","     619.5,\n","     1321.5,\n","     643.5,\n","     1361.5,\n","     672.5,\n","     1403.5,\n","     720.5,\n","     1428.5,\n","     765.5,\n","     1442.5,\n","     800.5,\n","     1445.5,\n","     860.5,\n","     1441.5,\n","     896.5,\n","     1427.5,\n","     942.5,\n","     1400.5,\n","     990.5,\n","     1361.5,\n","     1035.5,\n","     1316.5,\n","     1079.5,\n","     1269.5,\n","     1112.5,\n","     1228.5,\n","     1129.5,\n","     1198.5,\n","     1134.5,\n","     1207.5,\n","     1144.5,\n","     1210.5,\n","     1153.5,\n","     1190.5,\n","     1166.5,\n","     1177.5,\n","     1166.5,\n","     1172.5,\n","     1150.5,\n","     1174.5,\n","     1136.5,\n","     1170.5,\n","     1129.5,\n","     1153.5,\n","     1122.5,\n","     1127.5,\n","     1112.5,\n","     1104.5,\n","     1084.5,\n","     1061.5,\n","     1037.5,\n","     1032.5,\n","     989.5,\n","     1020.5,\n","     963.5]]}],\n"," 'file_name': 'balloon/train/34020010494_e5cb88e1c4_k.jpg',\n"," 'height': 1536,\n"," 'image_id': 0,\n"," 'width': 2048}"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"hA4n3A00jYVd","executionInfo":{"status":"ok","timestamp":1604900382363,"user_tz":-480,"elapsed":2426,"user":{"displayName":"曾珮瑜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPYSYGADc29eZMBqL2Y0yOZut6dqSPIMQ8_DJEacQ=s64","userId":"12040478592812319513"}},"outputId":"a9efdc02-0906-4724-910f-2202b00917ec","colab":{"base_uri":"https://localhost:8080/"}},"source":["# dataset_dicts = get_balloon_dicts(\"balloon/train\")\n","\n","dataset_dicts = DatasetCatalog.get('balloon_train')\n","print(len(dataset_dicts))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["61\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4MqCoDmqjbX7","executionInfo":{"status":"ok","timestamp":1604900388850,"user_tz":-480,"elapsed":3920,"user":{"displayName":"曾珮瑜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPYSYGADc29eZMBqL2Y0yOZut6dqSPIMQ8_DJEacQ=s64","userId":"12040478592812319513"}},"outputId":"2faf5903-4d19-4fe2-cc9e-6a001fdcb586","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1It9VrNMuQHI9Iz7nJmmt6c9zc9iZeLuv"}},"source":["for d in random.sample(dataset_dicts, 3):\n","    img = cv2.imread(d[\"file_name\"])\n","    visualizer = Visualizer(img[:, :, ::-1], metadata=balloon_metadata, scale=0.5)\n","    vis = visualizer.draw_dataset_dict(d)\n","    plt.figure(figsize=(20,10))\n","    plt.imshow(vis.get_image())"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"XslKc6pBjgs0","executionInfo":{"status":"ok","timestamp":1604900605556,"user_tz":-480,"elapsed":212395,"user":{"displayName":"曾珮瑜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPYSYGADc29eZMBqL2Y0yOZut6dqSPIMQ8_DJEacQ=s64","userId":"12040478592812319513"}},"outputId":"a86d32ff-9b6c-4b9e-b043-8e5f6ec51207","colab":{"base_uri":"https://localhost:8080/"}},"source":["cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","cfg.DATASETS.TRAIN = (\"balloon_train\",)\n","# cfg.DATASETS.TEST = (\"balloon_val\")\n","cfg.DATASETS.TEST = ()\n","cfg.DATALOADER.NUM_WORKERS = 2\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n","cfg.SOLVER.IMS_PER_BATCH = 2\n","cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n","cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon)\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = DefaultTrainer(cfg) \n","trainer.resume_or_load(resume=False)\n","trainer.train()\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["\u001b[32m[11/09 05:40:04 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","    (mask_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (mask_head): MaskRCNNConvUpsampleHead(\n","      (mask_fcn1): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn2): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn3): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn4): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (deconv_relu): ReLU()\n","      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","\u001b[32m[11/09 05:40:05 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 61 images left.\n","\u001b[32m[11/09 05:40:05 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n","\u001b[36m|  category  | #instances   |\n","|:----------:|:-------------|\n","|  balloon   | 255          |\n","|            |              |\u001b[0m\n","\u001b[32m[11/09 05:40:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[11/09 05:40:05 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[11/09 05:40:05 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n","\u001b[32m[11/09 05:40:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.17 MiB\n"],"name":"stdout"},{"output_type":"stream","text":["model_final_f10217.pkl: 178MB [00:06, 27.7MB/s]                           \n","Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[11/09 05:40:17 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/detectron2/structures/masks.py:345: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  item = item.nonzero().squeeze(1).cpu().numpy().tolist()\n","/usr/local/lib/python3.6/dist-packages/detectron2/structures/masks.py:345: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  item = item.nonzero().squeeze(1).cpu().numpy().tolist()\n","/usr/local/lib/python3.6/dist-packages/detectron2/modeling/roi_heads/fast_rcnn.py:217: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  num_fg = fg_inds.nonzero().numel()\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[11/09 05:40:29 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 19  total_loss: 2.05  loss_cls: 0.7338  loss_box_reg: 0.5875  loss_mask: 0.6949  loss_rpn_cls: 0.03294  loss_rpn_loc: 0.003273  time: 0.5945  data_time: 0.0227  lr: 4.9953e-06  max_mem: 2548M\n","\u001b[32m[11/09 05:40:42 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 39  total_loss: 2.108  loss_cls: 0.7147  loss_box_reg: 0.639  loss_mask: 0.6621  loss_rpn_cls: 0.04095  loss_rpn_loc: 0.007192  time: 0.6024  data_time: 0.0081  lr: 9.9902e-06  max_mem: 2548M\n","\u001b[32m[11/09 05:40:54 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 59  total_loss: 1.926  loss_cls: 0.6264  loss_box_reg: 0.6611  loss_mask: 0.6045  loss_rpn_cls: 0.02401  loss_rpn_loc: 0.008326  time: 0.6087  data_time: 0.0072  lr: 1.4985e-05  max_mem: 2672M\n","\u001b[32m[11/09 05:41:07 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 79  total_loss: 1.804  loss_cls: 0.542  loss_box_reg: 0.6517  loss_mask: 0.5434  loss_rpn_cls: 0.03707  loss_rpn_loc: 0.007098  time: 0.6141  data_time: 0.0060  lr: 1.998e-05  max_mem: 2672M\n","\u001b[32m[11/09 05:41:19 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 99  total_loss: 1.645  loss_cls: 0.4781  loss_box_reg: 0.6361  loss_mask: 0.4627  loss_rpn_cls: 0.02559  loss_rpn_loc: 0.008268  time: 0.6133  data_time: 0.0066  lr: 2.4975e-05  max_mem: 2672M\n","\u001b[32m[11/09 05:41:31 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 119  total_loss: 1.639  loss_cls: 0.4183  loss_box_reg: 0.7644  loss_mask: 0.4056  loss_rpn_cls: 0.0267  loss_rpn_loc: 0.005828  time: 0.6121  data_time: 0.0074  lr: 2.997e-05  max_mem: 2672M\n","\u001b[32m[11/09 05:41:44 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 139  total_loss: 1.506  loss_cls: 0.393  loss_box_reg: 0.6274  loss_mask: 0.3928  loss_rpn_cls: 0.03398  loss_rpn_loc: 0.01211  time: 0.6148  data_time: 0.0070  lr: 3.4965e-05  max_mem: 2672M\n","\u001b[32m[11/09 05:41:56 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 159  total_loss: 1.32  loss_cls: 0.3432  loss_box_reg: 0.6501  loss_mask: 0.3246  loss_rpn_cls: 0.02429  loss_rpn_loc: 0.007217  time: 0.6132  data_time: 0.0081  lr: 3.996e-05  max_mem: 2672M\n","\u001b[32m[11/09 05:42:08 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 179  total_loss: 1.281  loss_cls: 0.2898  loss_box_reg: 0.6686  loss_mask: 0.2877  loss_rpn_cls: 0.01556  loss_rpn_loc: 0.007019  time: 0.6121  data_time: 0.0087  lr: 4.4955e-05  max_mem: 2672M\n","\u001b[32m[11/09 05:42:20 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 199  total_loss: 1.224  loss_cls: 0.268  loss_box_reg: 0.6386  loss_mask: 0.283  loss_rpn_cls: 0.02693  loss_rpn_loc: 0.009569  time: 0.6126  data_time: 0.0081  lr: 4.995e-05  max_mem: 2672M\n","\u001b[32m[11/09 05:42:32 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 219  total_loss: 1.059  loss_cls: 0.2101  loss_box_reg: 0.6325  loss_mask: 0.2004  loss_rpn_cls: 0.01459  loss_rpn_loc: 0.004772  time: 0.6112  data_time: 0.0073  lr: 5.4945e-05  max_mem: 2672M\n","\u001b[32m[11/09 05:42:45 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 239  total_loss: 1.025  loss_cls: 0.206  loss_box_reg: 0.5901  loss_mask: 0.1897  loss_rpn_cls: 0.01662  loss_rpn_loc: 0.00772  time: 0.6118  data_time: 0.0103  lr: 5.994e-05  max_mem: 2672M\n","\u001b[32m[11/09 05:42:57 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 259  total_loss: 1.004  loss_cls: 0.1836  loss_box_reg: 0.5945  loss_mask: 0.1652  loss_rpn_cls: 0.0101  loss_rpn_loc: 0.007768  time: 0.6130  data_time: 0.0076  lr: 6.4935e-05  max_mem: 2672M\n","\u001b[32m[11/09 05:43:10 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 279  total_loss: 0.8739  loss_cls: 0.157  loss_box_reg: 0.5634  loss_mask: 0.1525  loss_rpn_cls: 0.006988  loss_rpn_loc: 0.00742  time: 0.6139  data_time: 0.0074  lr: 6.993e-05  max_mem: 2672M\n","\u001b[32m[11/09 05:43:24 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 299  total_loss: 0.8215  loss_cls: 0.1527  loss_box_reg: 0.4839  loss_mask: 0.118  loss_rpn_cls: 0.01769  loss_rpn_loc: 0.00533  time: 0.6152  data_time: 0.0074  lr: 7.4925e-05  max_mem: 2672M\n","\u001b[32m[11/09 05:43:24 d2.engine.hooks]: \u001b[0mOverall training speed: 298 iterations in 0:03:03 (0.6152 s / it)\n","\u001b[32m[11/09 05:43:24 d2.engine.hooks]: \u001b[0mTotal training time: 0:03:05 (0:00:02 on hooks)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sLeC9_IojoWO","executionInfo":{"status":"ok","timestamp":1604900622810,"user_tz":-480,"elapsed":1657,"user":{"displayName":"曾珮瑜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPYSYGADc29eZMBqL2Y0yOZut6dqSPIMQ8_DJEacQ=s64","userId":"12040478592812319513"}}},"source":["cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n","cfg.DATASETS.TEST = (\"balloon_val\", )\n","predictor = DefaultPredictor(cfg)\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"lb7eozNNj01_","executionInfo":{"status":"ok","timestamp":1604900629722,"user_tz":-480,"elapsed":5119,"user":{"displayName":"曾珮瑜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPYSYGADc29eZMBqL2Y0yOZut6dqSPIMQ8_DJEacQ=s64","userId":"12040478592812319513"}},"outputId":"d27092ff-8f06-48d5-875d-c77f0992008c","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ttw_LHhaCWA1AxotS2uEreJPh5TbMCQy"}},"source":["val_dicts = DatasetCatalog.get('balloon_val')\n","for d in random.sample(val_dicts, 3):    \n","    im = cv2.imread(d[\"file_name\"])\n","    outputs = predictor(im)\n","    v = Visualizer(im[:, :, ::-1],\n","                   metadata=balloon_metadata, \n","                   scale=0.8, \n","                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n","    )\n","    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    plt.figure(figsize=(20,10))\n","    plt.imshow(v.get_image()[:,:,::-1])\n","    "],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}